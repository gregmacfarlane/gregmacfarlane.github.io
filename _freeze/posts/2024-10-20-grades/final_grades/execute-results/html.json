{
  "hash": "a0cfc8153c36b65a4c593064c006a079",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"CCE 102 Grades Analysis\"\nauthor: \"Macfarlane\"\n---\n\nAfter midterm 1, I promised to evaluate at the end of the course how students\nperformed on that exam in comparison against their other work in the class. And\nif the midterm 1 grade was uniquely unrepresentative of the student's other\nwork, I would take that into account in a final grade. This is that analysis.\n\nFirst, I have an export directly from Learning Suite of all the grades\nin the course.\n\n\n\n## Exams\n\nFirst, I extract the exams and compute their weighted contribution to the\nexams grades as defined in Learning Suite.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grades on midterms and final\nexams <- all |> \n  transmute(\n    surname = `Last Name`, \n    id = `Net ID`, \n    midterm1 = `Infrastructure and Society Midterm (%)`/100,\n    midterm2 = (`Midterm 2` + `Midterm 2 - Instructor Graded`)/45,\n    final = `Sustainable Infrastructure Final Exam`/82, \n    exams_total = (midterm1 * 10 + midterm2 * 10 + final * 15) / 35\n  )\n```\n:::\n\nThe graphic below shows the grade distribution of students in the class. While\nthe mean is lower than I might like in general, it's not **really** low. But we'll\nmove forward regardless.\n::: {.cell}\n\n```{.r .cell-code}\nggplot(exams |> filter(midterm1 > 0), \n       aes(x = midterm1)) + geom_histogram()\n```\n\n::: {.cell-output-display}\n![](final_grades_files/figure-html/exam1-1.png){width=672}\n:::\n:::\n\n\nFirst, is there a big difference between student's scores on midterm 1 and \ntheir scores on other weighted exams? Yes, but there are lots of students\nwho did *better* on midterm 1 than on their other exams. It is interesting that\nthe students with high overall exam scores seemed to underperform on Midterm 1\nmore than students with lower overall scores. The red line in the plot below shows\nwhere the points would be if the midterm 1 score matched the overall exam score.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(exams |> filter(midterm1 > 0), aes(y = midterm1, x = exams_total)) + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  geom_point() + stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](final_grades_files/figure-html/all_exams-1.png){width=672}\n:::\n:::\n\n\n## Homework and other assignments.\n\nOf course, there are other assignments in the class. Let's get some of these \nin here as well. I'm not going to get all of the homework, but rather create a set\nof the most impactful assignments.\n\n::: {.cell}\n\n```{.r .cell-code}\nhomework <- all |> \n  transmute(\n    surname = `Last Name`, \n    id = `Net ID`, \n    sdg = `Sustainable Development Goals Essay`/15,\n    hwann = `HW: Annuities and Gradients`/25,\n    hwnpv = `HW: Equivalence`/25,\n    hwirr = `HW: Internal Rate of Return`/25,\n    interview  = `Culture Interview` / 20,\n    book = `Book Review`/10,\n    packback = `Packback`/100,\n  ) |> \n  mutate(\n    homework_total = (sdg*3 + hwann*3 + hwnpv*3 + hwirr*2 + interview*3 + book*3 + packback * 8)/(25)\n  )\n\ndata <- left_join(exams, homework, by = c(\"surname\", \"id\"))\n```\n:::\n\nThe graph below shows midterm 1 against all of the other (non-exam homework). \nIt's basically the same trend as the last plot.\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data |> filter(midterm1 > 0), aes(y = midterm1, x = homework_total)) + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  geom_point() + stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](final_grades_files/figure-html/homework_asses-1.png){width=672}\n:::\n:::\n\n\n## Prep\n\nLet's see what share of the prep assignments the students did.\n\n::: {.cell}\n\n```{.r .cell-code}\nprep <- all |> \n  select( surname = `Last Name`,  id = `Net ID`,  contains(\"Pre-class\" ) ) |> \n  select( surname, id,  contains(\"%\" ) ) |> \n  pivot_longer(!surname:id, names_to = \"assignment\", values_to = \"value\") |> \n  group_by(id) |> \n  mutate(complete = value > 50) |> \n  summarise(completed = sum(complete) / 24)\n\ndata <- left_join(data, prep, by = \"id\")\n```\n:::\n\nThere is a very slight correlation between this.\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data |> filter(midterm1 > 0), aes(y = midterm1, x = completed)) + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  geom_jitter() + stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](final_grades_files/figure-html/prep2-1.png){width=672}\n:::\n:::\n\n\n## Model\n\nLet's build a logistic model predicting the midterm 1 score as a function of \nthe student's other work. This is a quasi-binomial model. It would be interesting\nto explore some [Bayesian modeling techniques for this problem](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#b-beta-regression-bayesian-style), but I'm time constrained.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- glm(midterm1 ~ midterm2 + final + sdg + hwann + hwnpv + hwirr + \n               interview + book + packback + completed, data = data, \n             family = quasibinomial())\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modelsummary)\nmodelsummary(model, stars = TRUE, estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n             statistic = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"NAborder-bottom: 0; width: auto !important; margin-left: auto; margin-right: auto;\" class=\"table\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> −0.537 [−1.916, 0.848] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> midterm2 </td>\n   <td style=\"text-align:center;\"> 0.624 [−0.369, 1.605] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> final </td>\n   <td style=\"text-align:center;\"> 0.103 [−1.037, 1.244] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sdg </td>\n   <td style=\"text-align:center;\"> 0.700 [−0.407, 1.816] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> hwann </td>\n   <td style=\"text-align:center;\"> 0.276 [−0.304, 0.848] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> hwnpv </td>\n   <td style=\"text-align:center;\"> 0.601 [0.060, 1.143] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> hwirr </td>\n   <td style=\"text-align:center;\"> 0.068 [−0.388, 0.519] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> interview </td>\n   <td style=\"text-align:center;\"> −0.340 [−1.008, 0.285] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> book </td>\n   <td style=\"text-align:center;\"> −0.210 [−0.892, 0.441] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> packback </td>\n   <td style=\"text-align:center;\"> 0.149 [−0.580, 0.872] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\"> completed </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> 0.010 [−1.380, 1.397] </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 113 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> F </td>\n   <td style=\"text-align:center;\"> 2.754 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 0.14 </td>\n  </tr>\n</tbody>\n<tfoot><tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001</td></tr></tfoot>\n</table>\n\n`````\n:::\n:::\n\nThese are interesting model results. Basically the only element (here) that affects\nthe midterm 1 score is the grade on the NPV homework. Gettign a better score on the \ninterview and book review has a small negative relationship, but isn't very predictive.\n\n\nWhat if we do random forest regression instead? This gets us similar results. \nUnsurprisingly, the total exam score is the most important element. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'randomForest' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrandomForest 4.7-1.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nType rfNews() to see new features/changes/bug fixes.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'randomForest'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    combine\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:ggplot2':\n\n    margin\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(42)\nmidterm1.rf <- randomForest(midterm1 ~ ., data = data |> select(-surname, -id), \n                            mtry=3, importance = TRUE, na.action = na.omit)\n## Show \"importance\" of variables: higher value mean more important:\nround(importance(midterm1.rf), 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               %IncMSE IncNodePurity\nmidterm2          6.89          0.23\nfinal             7.72          0.29\nexams_total      12.86          0.65\nsdg               1.20          0.16\nhwann            -0.97          0.14\nhwnpv             5.11          0.27\nhwirr             1.90          0.11\ninterview        -0.85          0.08\nbook             -0.89          0.07\npackback          2.01          0.13\nhomework_total    5.55          0.24\ncompleted         1.27          0.14\n```\n\n\n:::\n:::\n\nLet's throw the predicted value on the dataset and plot how it does. Overall,\nthis is a pretty good fit and shows that midterm 1 is not necessarily out of line with the other assessments students have done. Midterm 1 did seem to benefit students who have somewhat underperformed on their other work, while penalizing students who have been generally better prepared overall. Some adjustment to the class curve is probably warranted, mostly at the upper end of the grade distribution. \n::: {.cell}\n\n```{.r .cell-code}\ndata$predict_m1 <- predict(midterm1.rf)\nggplot(data |> filter(midterm1 > 0), aes(x = midterm1, y = predict_m1)) + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  geom_point() + stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](final_grades_files/figure-html/rfpredict-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "final_grades_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}